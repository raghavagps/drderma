{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ce59021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy, categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d69c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"D:\\IIIT-D\\Summer Semester\\CAPSTONE PROJECT\\Complete Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3f93215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40253 images belonging to 7 classes.\n",
      "Found 1000 images belonging to 7 classes.\n",
      "Found 1006 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = root+'/Hair Removed Images/train'\n",
    "val_dir = root+'/Hair Removed Images/val'\n",
    "test_dir = root+'/Hair Removed Images/test'\n",
    "datagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=8,class_mode='categorical',seed=42)\n",
    "\n",
    "val_data = datagen.flow_from_directory(val_dir,target_size=(224,224),batch_size=8,class_mode='categorical',seed=42)\n",
    "\n",
    "test_data = datagen.flow_from_directory(test_dir,target_size=(224,224),batch_size=8,class_mode='categorical',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b87324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 100s 1us/step\n",
      "96124928/96112376 [==============================] - 100s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "num_labels = 7\n",
    "\n",
    "base_model = InceptionV3(include_top=True, pooling = 'max', weights = 'imagenet',classes=1000)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels, activation = 'softmax',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "094be201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_2_acc(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "\n",
    "def top_3_acc(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "lrReduction=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                              factor=0.5,\n",
    "                              patience=2,\n",
    "                              verbose=1,\n",
    "                              mode='auto',\n",
    "                              min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13aaae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 1000)              23851784  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               128128    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 23,980,815\n",
      "Trainable params: 23,946,383\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy',\n",
    "                                                                        top_2_acc,\n",
    "                                                                        top_3_acc,\n",
    "                                                                        tf.metrics.AUC(curve='ROC'),\n",
    "                                                                        tfa.metrics.MatthewsCorrelationCoefficient(num_classes=7)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fda6945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5031/5031 [==============================] - 648s 128ms/step - loss: 1.8991 - accuracy: 0.1881 - top_2_acc: 0.3476 - top_3_acc: 0.5014 - auc_3: 0.5773 - MatthewsCorrelationCoefficient: 0.0517 - val_loss: 1.6789 - val_accuracy: 0.5370 - val_top_2_acc: 0.6440 - val_top_3_acc: 0.7560 - val_auc_3: 0.7944 - val_MatthewsCorrelationCoefficient: 0.0856\n",
      "Epoch 2/50\n",
      "5031/5031 [==============================] - 640s 127ms/step - loss: 1.7556 - accuracy: 0.2826 - top_2_acc: 0.4748 - top_3_acc: 0.6404 - auc_3: 0.6888 - MatthewsCorrelationCoefficient: 0.1709 - val_loss: 1.5012 - val_accuracy: 0.5790 - val_top_2_acc: 0.6830 - val_top_3_acc: 0.7930 - val_auc_3: 0.8249 - val_MatthewsCorrelationCoefficient: 0.1494\n",
      "Epoch 3/50\n",
      "5031/5031 [==============================] - 639s 127ms/step - loss: 1.6595 - accuracy: 0.3300 - top_2_acc: 0.5448 - top_3_acc: 0.7203 - auc_3: 0.7406 - MatthewsCorrelationCoefficient: 0.2249 - val_loss: 1.2587 - val_accuracy: 0.5730 - val_top_2_acc: 0.6790 - val_top_3_acc: 0.7810 - val_auc_3: 0.8526 - val_MatthewsCorrelationCoefficient: 0.3011\n",
      "Epoch 4/50\n",
      "5031/5031 [==============================] - 639s 127ms/step - loss: 1.5583 - accuracy: 0.3850 - top_2_acc: 0.5842 - top_3_acc: 0.7461 - auc_3: 0.7775 - MatthewsCorrelationCoefficient: 0.2884 - val_loss: 1.0224 - val_accuracy: 0.6300 - val_top_2_acc: 0.7610 - val_top_3_acc: 0.8440 - val_auc_3: 0.9115 - val_MatthewsCorrelationCoefficient: 0.2985\n",
      "Epoch 5/50\n",
      "5031/5031 [==============================] - 641s 127ms/step - loss: 1.4827 - accuracy: 0.4078 - top_2_acc: 0.6091 - top_3_acc: 0.7571 - auc_3: 0.7989 - MatthewsCorrelationCoefficient: 0.3118 - val_loss: 0.9926 - val_accuracy: 0.6440 - val_top_2_acc: 0.7880 - val_top_3_acc: 0.8910 - val_auc_3: 0.9174 - val_MatthewsCorrelationCoefficient: 0.2816\n",
      "Epoch 6/50\n",
      "5031/5031 [==============================] - 639s 127ms/step - loss: 1.4493 - accuracy: 0.4175 - top_2_acc: 0.6334 - top_3_acc: 0.7843 - auc_3: 0.8106 - MatthewsCorrelationCoefficient: 0.3227 - val_loss: 0.9838 - val_accuracy: 0.5980 - val_top_2_acc: 0.7570 - val_top_3_acc: 0.9160 - val_auc_3: 0.9170 - val_MatthewsCorrelationCoefficient: 0.2670\n",
      "Epoch 7/50\n",
      "5031/5031 [==============================] - 639s 127ms/step - loss: 1.3778 - accuracy: 0.4497 - top_2_acc: 0.6568 - top_3_acc: 0.7998 - auc_3: 0.8301 - MatthewsCorrelationCoefficient: 0.3595 - val_loss: 1.0470 - val_accuracy: 0.6340 - val_top_2_acc: 0.7570 - val_top_3_acc: 0.8740 - val_auc_3: 0.9091 - val_MatthewsCorrelationCoefficient: 0.2074\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/50\n",
      "5031/5031 [==============================] - 642s 128ms/step - loss: 1.3760 - accuracy: 0.4507 - top_2_acc: 0.6634 - top_3_acc: 0.8030 - auc_3: 0.8316 - MatthewsCorrelationCoefficient: 0.3610 - val_loss: 0.9135 - val_accuracy: 0.6840 - val_top_2_acc: 0.8030 - val_top_3_acc: 0.9180 - val_auc_3: 0.9290 - val_MatthewsCorrelationCoefficient: 0.3198\n",
      "Epoch 9/50\n",
      "5031/5031 [==============================] - 711s 141ms/step - loss: 1.2986 - accuracy: 0.4847 - top_2_acc: 0.6867 - top_3_acc: 0.8190 - auc_3: 0.8510 - MatthewsCorrelationCoefficient: 0.4010 - val_loss: 0.9368 - val_accuracy: 0.6180 - val_top_2_acc: 0.8110 - val_top_3_acc: 0.9220 - val_auc_3: 0.9263 - val_MatthewsCorrelationCoefficient: 0.2828\n",
      "Epoch 10/50\n",
      "5031/5031 [==============================] - 706s 140ms/step - loss: 1.2436 - accuracy: 0.5045 - top_2_acc: 0.7064 - top_3_acc: 0.8369 - auc_3: 0.8645 - MatthewsCorrelationCoefficient: 0.4235 - val_loss: 0.9668 - val_accuracy: 0.5970 - val_top_2_acc: 0.8240 - val_top_3_acc: 0.9260 - val_auc_3: 0.9242 - val_MatthewsCorrelationCoefficient: 0.3150\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/50\n",
      "5031/5031 [==============================] - 714s 142ms/step - loss: 1.1901 - accuracy: 0.5302 - top_2_acc: 0.7280 - top_3_acc: 0.8525 - auc_3: 0.8769 - MatthewsCorrelationCoefficient: 0.4530 - val_loss: 0.9361 - val_accuracy: 0.6830 - val_top_2_acc: 0.8080 - val_top_3_acc: 0.9160 - val_auc_3: 0.9254 - val_MatthewsCorrelationCoefficient: 0.3742\n",
      "Epoch 12/50\n",
      "5031/5031 [==============================] - 640s 127ms/step - loss: 1.1589 - accuracy: 0.5434 - top_2_acc: 0.7389 - top_3_acc: 0.8589 - auc_3: 0.8839 - MatthewsCorrelationCoefficient: 0.4685 - val_loss: 0.8836 - val_accuracy: 0.6380 - val_top_2_acc: 0.8480 - val_top_3_acc: 0.9480 - val_auc_3: 0.9347 - val_MatthewsCorrelationCoefficient: 0.3426\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/50\n",
      "5031/5031 [==============================] - 641s 127ms/step - loss: 1.1345 - accuracy: 0.5517 - top_2_acc: 0.7409 - top_3_acc: 0.8597 - auc_3: 0.8885 - MatthewsCorrelationCoefficient: 0.4780 - val_loss: 0.8302 - val_accuracy: 0.6630 - val_top_2_acc: 0.8100 - val_top_3_acc: 0.9480 - val_auc_3: 0.9408 - val_MatthewsCorrelationCoefficient: 0.3625\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "step_size_train=train_data.n//train_data.batch_size\n",
    "history = model.fit_generator(generator=train_data,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   validation_data=val_data,\n",
    "                    epochs=50, \n",
    "                    verbose = 1,\n",
    "                    callbacks=[lrReduction,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f92a1d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5032/5032 [==============================] - 200s 40ms/step - loss: 0.9624 - accuracy: 0.6195 - top_2_acc: 0.8036 - top_3_acc: 0.9044 - auc_3: 0.9220 - MatthewsCorrelationCoefficient: 0.5578\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy,top_2,top_3,auc,mcc = model.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1b4c322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 5s 40ms/step - loss: 0.8302 - accuracy: 0.6630 - top_2_acc: 0.8100 - top_3_acc: 0.9480 - auc_3: 0.9408 - MatthewsCorrelationCoefficient: 0.3625\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy,top_2,top_3,auc,mcc = model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a50e4c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 10s 81ms/step - loss: 0.8977 - accuracy: 0.6412 - top_2_acc: 0.7734 - top_3_acc: 0.9245 - auc_3: 0.9304 - MatthewsCorrelationCoefficient: 0.3251\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy,top_2,top_3,auc,mcc = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4493aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.09      0.14        34\n",
      "           1       0.33      0.52      0.40        52\n",
      "           2       0.25      0.15      0.19       111\n",
      "           3       0.20      0.08      0.12        12\n",
      "           4       0.26      0.38      0.31       112\n",
      "           5       0.82      0.81      0.82       670\n",
      "           6       0.59      0.67      0.62        15\n",
      "\n",
      "    accuracy                           0.64      1006\n",
      "   macro avg       0.40      0.39      0.37      1006\n",
      "weighted avg       0.64      0.64      0.64      1006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "true_test_labels=test_data.labels\n",
    "\n",
    "true_test_labels=np.array(true_test_labels)\n",
    "\n",
    "np.unique(true_test_labels,return_counts=True)\n",
    "\n",
    "pred_test_labels=model.predict(test_data)\n",
    "\n",
    "pred_test_labels=np.argmax(pred_test_labels,axis=1)\n",
    "\n",
    "metrics.accuracy_score(true_test_labels,pred_test_labels)\n",
    "\n",
    "report = metrics.classification_report(true_test_labels,pred_test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b365132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"D:\\IIIT-D\\Summer Semester\\CAPSTONE PROJECT\\Saved Models\\Inception_V3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398de13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
