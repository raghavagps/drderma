{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce59021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy, categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d69c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"D:\\IIIT-D\\Summer Semester\\CAPSTONE PROJECT\\Complete Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f93215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40253 images belonging to 7 classes.\n",
      "Found 1000 images belonging to 7 classes.\n",
      "Found 1006 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = root+'/Hair Removed Images/train'\n",
    "val_dir = root+'/Hair Removed Images/val'\n",
    "test_dir = root+'/Hair Removed Images/test'\n",
    "datagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=4,class_mode='categorical',seed=42)\n",
    "\n",
    "val_data = datagen.flow_from_directory(val_dir,target_size=(224,224),batch_size=4,class_mode='categorical',seed=42)\n",
    "\n",
    "test_data = datagen.flow_from_directory(test_dir,target_size=(224,224),batch_size=4,class_mode='categorical',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b87324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "num_labels = 7\n",
    "\n",
    "num_labels = 7\n",
    "\n",
    "base_model = ResNet101(include_top=False, input_shape=(128, 128, 3),pooling = 'avg', weights = 'imagenet')\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels, activation = 'softmax',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "094be201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_2_acc(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "\n",
    "def top_3_acc(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "lrReduction=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                              factor=0.5,\n",
    "                              patience=2,\n",
    "                              verbose=1,\n",
    "                              mode='auto',\n",
    "                              min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13aaae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet101 (Functional)       (None, 2048)              42658176  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 42,921,351\n",
      "Trainable params: 42,816,007\n",
      "Non-trainable params: 105,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy',\n",
    "                                                                        top_2_acc,\n",
    "                                                                        top_3_acc,\n",
    "                                                                        tf.metrics.AUC(curve='ROC'),\n",
    "                                                                        tfa.metrics.MatthewsCorrelationCoefficient(num_classes=7)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fda6945d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10063/10063 [==============================] - 1742s 172ms/step - loss: 1.9181 - accuracy: 0.1849 - top_2_acc: 0.3405 - top_3_acc: 0.4888 - auc_2: 0.5668 - MatthewsCorrelationCoefficient: 0.0486 - val_loss: 2.0236 - val_accuracy: 0.0480 - val_top_2_acc: 0.1310 - val_top_3_acc: 0.2330 - val_auc_2: 0.4311 - val_MatthewsCorrelationCoefficient: -0.0070\n",
      "Epoch 2/50\n",
      "10063/10063 [==============================] - 1729s 172ms/step - loss: 1.7536 - accuracy: 0.2837 - top_2_acc: 0.4592 - top_3_acc: 0.6092 - auc_2: 0.6832 - MatthewsCorrelationCoefficient: 0.1685 - val_loss: 1.6170 - val_accuracy: 0.4080 - val_top_2_acc: 0.4870 - val_top_3_acc: 0.6030 - val_auc_2: 0.7270 - val_MatthewsCorrelationCoefficient: 0.1880\n",
      "Epoch 3/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 1.7472 - accuracy: 0.2910 - top_2_acc: 0.4685 - top_3_acc: 0.6173 - auc_2: 0.6893 - MatthewsCorrelationCoefficient: 0.1774 - val_loss: 1.3249 - val_accuracy: 0.5370 - val_top_2_acc: 0.6510 - val_top_3_acc: 0.7410 - val_auc_2: 0.8378 - val_MatthewsCorrelationCoefficient: 0.2172\n",
      "Epoch 4/50\n",
      "10063/10063 [==============================] - 1729s 172ms/step - loss: 1.6231 - accuracy: 0.3466 - top_2_acc: 0.5321 - top_3_acc: 0.6834 - auc_2: 0.7436 - MatthewsCorrelationCoefficient: 0.2464 - val_loss: 1.3487 - val_accuracy: 0.5040 - val_top_2_acc: 0.6180 - val_top_3_acc: 0.7510 - val_auc_2: 0.8352 - val_MatthewsCorrelationCoefficient: 0.2726\n",
      "Epoch 5/50\n",
      "10063/10063 [==============================] - 1729s 172ms/step - loss: 1.4978 - accuracy: 0.4078 - top_2_acc: 0.5983 - top_3_acc: 0.7414 - auc_2: 0.7906 - MatthewsCorrelationCoefficient: 0.3188 - val_loss: 1.7900 - val_accuracy: 0.5310 - val_top_2_acc: 0.6830 - val_top_3_acc: 0.8510 - val_auc_2: 0.8426 - val_MatthewsCorrelationCoefficient: 0.1793\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/50\n",
      "10063/10063 [==============================] - 1729s 172ms/step - loss: 1.3088 - accuracy: 0.4858 - top_2_acc: 0.6833 - top_3_acc: 0.8161 - auc_2: 0.8490 - MatthewsCorrelationCoefficient: 0.4058 - val_loss: 3.7165 - val_accuracy: 0.6850 - val_top_2_acc: 0.8260 - val_top_3_acc: 0.9270 - val_auc_2: 0.9066 - val_MatthewsCorrelationCoefficient: 0.3241\n",
      "Epoch 7/50\n",
      "10063/10063 [==============================] - 1729s 172ms/step - loss: 1.1695 - accuracy: 0.5440 - top_2_acc: 0.7423 - top_3_acc: 0.8664 - auc_2: 0.8827 - MatthewsCorrelationCoefficient: 0.4708 - val_loss: 6.7021 - val_accuracy: 0.6570 - val_top_2_acc: 0.8290 - val_top_3_acc: 0.9240 - val_auc_2: 0.9214 - val_MatthewsCorrelationCoefficient: 0.3611\n",
      "Epoch 8/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 1.0753 - accuracy: 0.5782 - top_2_acc: 0.7765 - top_3_acc: 0.8916 - auc_2: 0.9018 - MatthewsCorrelationCoefficient: 0.5097 - val_loss: 4.1276 - val_accuracy: 0.6650 - val_top_2_acc: 0.8050 - val_top_3_acc: 0.9330 - val_auc_2: 0.9072 - val_MatthewsCorrelationCoefficient: 0.3547\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 0.9634 - accuracy: 0.6216 - top_2_acc: 0.8151 - top_3_acc: 0.9183 - auc_2: 0.9214 - MatthewsCorrelationCoefficient: 0.5600 - val_loss: 3.4717 - val_accuracy: 0.6720 - val_top_2_acc: 0.8500 - val_top_3_acc: 0.9410 - val_auc_2: 0.9247 - val_MatthewsCorrelationCoefficient: 0.3704\n",
      "Epoch 10/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.9082 - accuracy: 0.6456 - top_2_acc: 0.8302 - top_3_acc: 0.9275 - auc_2: 0.9302 - MatthewsCorrelationCoefficient: 0.5880 - val_loss: 5.6987 - val_accuracy: 0.6920 - val_top_2_acc: 0.8610 - val_top_3_acc: 0.9540 - val_auc_2: 0.9315 - val_MatthewsCorrelationCoefficient: 0.3885\n",
      "Epoch 11/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.8671 - accuracy: 0.6629 - top_2_acc: 0.8424 - top_3_acc: 0.9371 - auc_2: 0.9363 - MatthewsCorrelationCoefficient: 0.6080 - val_loss: 2.9019 - val_accuracy: 0.6870 - val_top_2_acc: 0.8320 - val_top_3_acc: 0.9390 - val_auc_2: 0.9233 - val_MatthewsCorrelationCoefficient: 0.3859\n",
      "Epoch 12/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.8293 - accuracy: 0.6810 - top_2_acc: 0.8543 - top_3_acc: 0.9424 - auc_2: 0.9420 - MatthewsCorrelationCoefficient: 0.6289 - val_loss: 18.6574 - val_accuracy: 0.6770 - val_top_2_acc: 0.8560 - val_top_3_acc: 0.9540 - val_auc_2: 0.9128 - val_MatthewsCorrelationCoefficient: 0.3960\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 0.7681 - accuracy: 0.7013 - top_2_acc: 0.8697 - top_3_acc: 0.9539 - auc_2: 0.9499 - MatthewsCorrelationCoefficient: 0.6525 - val_loss: 48.4309 - val_accuracy: 0.6840 - val_top_2_acc: 0.8710 - val_top_3_acc: 0.9580 - val_auc_2: 0.9127 - val_MatthewsCorrelationCoefficient: 0.4014\n",
      "Epoch 14/50\n",
      "10063/10063 [==============================] - 1732s 172ms/step - loss: 0.7401 - accuracy: 0.7123 - top_2_acc: 0.8764 - top_3_acc: 0.9560 - auc_2: 0.9535 - MatthewsCorrelationCoefficient: 0.6653 - val_loss: 74.4468 - val_accuracy: 0.6850 - val_top_2_acc: 0.8780 - val_top_3_acc: 0.9650 - val_auc_2: 0.9120 - val_MatthewsCorrelationCoefficient: 0.3951\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/50\n",
      "10063/10063 [==============================] - 1732s 172ms/step - loss: 0.6960 - accuracy: 0.7296 - top_2_acc: 0.8881 - top_3_acc: 0.9629 - auc_2: 0.9588 - MatthewsCorrelationCoefficient: 0.6853 - val_loss: 78.1825 - val_accuracy: 0.6930 - val_top_2_acc: 0.8720 - val_top_3_acc: 0.9700 - val_auc_2: 0.9189 - val_MatthewsCorrelationCoefficient: 0.4197\n",
      "Epoch 16/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.6858 - accuracy: 0.7326 - top_2_acc: 0.8902 - top_3_acc: 0.9644 - auc_2: 0.9599 - MatthewsCorrelationCoefficient: 0.6888 - val_loss: 117.2227 - val_accuracy: 0.6980 - val_top_2_acc: 0.8670 - val_top_3_acc: 0.9650 - val_auc_2: 0.9203 - val_MatthewsCorrelationCoefficient: 0.4346\n",
      "Epoch 17/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 0.6634 - accuracy: 0.7406 - top_2_acc: 0.8962 - top_3_acc: 0.9677 - auc_2: 0.9625 - MatthewsCorrelationCoefficient: 0.6981 - val_loss: 129.2504 - val_accuracy: 0.6940 - val_top_2_acc: 0.8870 - val_top_3_acc: 0.9640 - val_auc_2: 0.9151 - val_MatthewsCorrelationCoefficient: 0.4256\n",
      "Epoch 18/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.6482 - accuracy: 0.7465 - top_2_acc: 0.8973 - top_3_acc: 0.9677 - auc_2: 0.9640 - MatthewsCorrelationCoefficient: 0.7050 - val_loss: 158.8659 - val_accuracy: 0.6860 - val_top_2_acc: 0.8790 - val_top_3_acc: 0.9690 - val_auc_2: 0.9102 - val_MatthewsCorrelationCoefficient: 0.4216\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 19/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 0.6272 - accuracy: 0.7547 - top_2_acc: 0.9066 - top_3_acc: 0.9704 - auc_2: 0.9662 - MatthewsCorrelationCoefficient: 0.7144 - val_loss: 119.9209 - val_accuracy: 0.7020 - val_top_2_acc: 0.8780 - val_top_3_acc: 0.9720 - val_auc_2: 0.9166 - val_MatthewsCorrelationCoefficient: 0.4409\n",
      "Epoch 20/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 0.6199 - accuracy: 0.7579 - top_2_acc: 0.9072 - top_3_acc: 0.9725 - auc_2: 0.9669 - MatthewsCorrelationCoefficient: 0.7180 - val_loss: 176.3619 - val_accuracy: 0.6890 - val_top_2_acc: 0.8900 - val_top_3_acc: 0.9700 - val_auc_2: 0.9101 - val_MatthewsCorrelationCoefficient: 0.4188\n",
      "Epoch 21/50\n",
      "10063/10063 [==============================] - 1730s 172ms/step - loss: 0.6090 - accuracy: 0.7642 - top_2_acc: 0.9095 - top_3_acc: 0.9734 - auc_2: 0.9682 - MatthewsCorrelationCoefficient: 0.7256 - val_loss: 109.8442 - val_accuracy: 0.6990 - val_top_2_acc: 0.8910 - val_top_3_acc: 0.9720 - val_auc_2: 0.9210 - val_MatthewsCorrelationCoefficient: 0.4254\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 22/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.5974 - accuracy: 0.7663 - top_2_acc: 0.9110 - top_3_acc: 0.9740 - auc_2: 0.9694 - MatthewsCorrelationCoefficient: 0.7280 - val_loss: 154.1696 - val_accuracy: 0.7000 - val_top_2_acc: 0.8840 - val_top_3_acc: 0.9700 - val_auc_2: 0.9196 - val_MatthewsCorrelationCoefficient: 0.4347\n",
      "Epoch 23/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.5897 - accuracy: 0.7682 - top_2_acc: 0.9125 - top_3_acc: 0.9748 - auc_2: 0.9700 - MatthewsCorrelationCoefficient: 0.7302 - val_loss: 206.4650 - val_accuracy: 0.6960 - val_top_2_acc: 0.8790 - val_top_3_acc: 0.9700 - val_auc_2: 0.9065 - val_MatthewsCorrelationCoefficient: 0.4392\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 24/50\n",
      "10063/10063 [==============================] - 1731s 172ms/step - loss: 0.5863 - accuracy: 0.7703 - top_2_acc: 0.9148 - top_3_acc: 0.9763 - auc_2: 0.9704 - MatthewsCorrelationCoefficient: 0.7326 - val_loss: 146.2075 - val_accuracy: 0.7010 - val_top_2_acc: 0.8910 - val_top_3_acc: 0.9700 - val_auc_2: 0.9174 - val_MatthewsCorrelationCoefficient: 0.4346\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "step_size_train=train_data.n//train_data.batch_size\n",
    "history = model.fit_generator(generator=train_data,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   validation_data=val_data,\n",
    "                    epochs=50, \n",
    "                    verbose = 1,\n",
    "                    callbacks=[lrReduction,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92a1d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10064/10064 [==============================] - 527s 52ms/step - loss: 240.5943 - accuracy: 0.7210 - top_2_acc: 0.9217 - top_3_acc: 0.9724 - auc_2: 0.8995 - MatthewsCorrelationCoefficient: 0.6797\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy,top_2,top_3,auc,mcc = model.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1b4c322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 13s 52ms/step - loss: 146.2075 - accuracy: 0.7010 - top_2_acc: 0.8910 - top_3_acc: 0.9700 - auc_2: 0.9174 - MatthewsCorrelationCoefficient: 0.4346\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy,top_2,top_3,auc,mcc = model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a50e4c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 14s 54ms/step - loss: 144.7224 - accuracy: 0.6889 - top_2_acc: 0.8718 - top_3_acc: 0.9453 - auc_2: 0.9106 - MatthewsCorrelationCoefficient: 0.4226\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy,top_2,top_3,auc,mcc = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4493aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.44      0.49        34\n",
      "           1       0.44      0.54      0.49        52\n",
      "           2       0.43      0.48      0.45       111\n",
      "           3       0.33      0.33      0.33        12\n",
      "           4       0.50      0.23      0.32       112\n",
      "           5       0.84      0.83      0.83       670\n",
      "           6       0.17      0.73      0.28        15\n",
      "\n",
      "    accuracy                           0.69      1006\n",
      "   macro avg       0.47      0.51      0.46      1006\n",
      "weighted avg       0.71      0.69      0.69      1006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "true_test_labels=test_data.labels\n",
    "\n",
    "true_test_labels=np.array(true_test_labels)\n",
    "\n",
    "np.unique(true_test_labels,return_counts=True)\n",
    "\n",
    "pred_test_labels=model.predict(test_data)\n",
    "\n",
    "pred_test_labels=np.argmax(pred_test_labels,axis=1)\n",
    "\n",
    "metrics.accuracy_score(true_test_labels,pred_test_labels)\n",
    "\n",
    "report = metrics.classification_report(true_test_labels,pred_test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b365132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"D:\\IIIT-D\\Summer Semester\\CAPSTONE PROJECT\\Saved Models\\Resnet_101.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739145ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
